{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMEANO5u7VkS"
      },
      "source": [
        "# Provided code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtLHykNf7DC5",
        "outputId": "daad2641-3365-4ed2-f0c9-36839f844fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: open_spiel in /opt/anaconda3/envs/emg/lib/python3.14/site-packages (1.6.9)\n",
            "Requirement already satisfied: pip>=20.0.2 in /Users/guanyulu/.local/lib/python3.14/site-packages (from open_spiel) (25.3)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /Users/guanyulu/.local/lib/python3.14/site-packages (from open_spiel) (25.4.0)\n",
            "Requirement already satisfied: absl-py>=0.10.0 in /Users/guanyulu/.local/lib/python3.14/site-packages (from open_spiel) (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.21.5 in /Users/guanyulu/.local/lib/python3.14/site-packages (from open_spiel) (2.3.5)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /opt/anaconda3/envs/emg/lib/python3.14/site-packages (from open_spiel) (1.16.3)\n",
            "Requirement already satisfied: ml-collections>=0.1.1 in /Users/guanyulu/.local/lib/python3.14/site-packages (from open_spiel) (1.1.0)\n",
            "Requirement already satisfied: PyYAML in /opt/anaconda3/envs/emg/lib/python3.14/site-packages (from ml-collections>=0.1.1->open_spiel) (6.0.3)\n"
          ]
        }
      ],
      "source": [
        "# Install open spiel\n",
        "!pip install --upgrade open_spiel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qkTsndo37PAv"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "\n",
        "from open_spiel.python import rl_agent\n",
        "from open_spiel.python import rl_environment\n",
        "import pyspiel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Q6bwFdsT7l32"
      },
      "outputs": [],
      "source": [
        "# Some helper classes and functions.\n",
        "# DO NOT CHANGE.\n",
        "\n",
        "class BotAgent(rl_agent.AbstractAgent):\n",
        "  \"\"\"Agent class that wraps a bot.\n",
        "\n",
        "  Note, the environment must include the OpenSpiel state in its observations,\n",
        "  which means it must have been created with use_full_state=True.\n",
        "\n",
        "  This is a simple wrapper that lets the RPS bots be interpreted as agents under\n",
        "  the RL API.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, num_actions, bot, name=\"bot_agent\"):\n",
        "    assert num_actions > 0\n",
        "    self._bot = bot\n",
        "    self._num_actions = num_actions\n",
        "\n",
        "  def restart(self):\n",
        "    self._bot.restart()\n",
        "\n",
        "  def step(self, time_step, is_evaluation=False):\n",
        "    # If it is the end of the episode, don't select an action.\n",
        "    if time_step.last():\n",
        "      return\n",
        "    _, state = pyspiel.deserialize_game_and_state(\n",
        "        time_step.observations[\"serialized_state\"])\n",
        "    action = self._bot.step(state)\n",
        "    probs = np.zeros(self._num_actions)\n",
        "    probs[action] = 1.0\n",
        "    return rl_agent.StepOutput(action=action, probs=probs)\n",
        "\n",
        "\n",
        "#  We will use this function to evaluate the agents. Do not change.\n",
        "\n",
        "def eval_agents(env, agents, num_players, num_episodes, verbose=False):\n",
        "  \"\"\"Evaluate the agent.\n",
        "\n",
        "  Runs a number of episodes and returns the average returns for each agent as\n",
        "  a numpy array.\n",
        "\n",
        "  Arguments:\n",
        "    env: the RL environment,\n",
        "    agents: a list of agents (size 2),\n",
        "    num_players: number of players in the game (for RRPS, this is 2),\n",
        "    num_episodes: number of evaluation episodes to run.\n",
        "    verbose: whether to print updates after each episode.\n",
        "  \"\"\"\n",
        "  sum_episode_rewards = np.zeros(num_players)\n",
        "  for ep in range(num_episodes):\n",
        "    for agent in agents:\n",
        "      # Bots need to be restarted at the start of the episode.\n",
        "      if hasattr(agent, \"restart\"):\n",
        "        agent.restart()\n",
        "    time_step = env.reset()\n",
        "    episode_rewards = np.zeros(num_players)\n",
        "    while not time_step.last():\n",
        "      agents_output = [\n",
        "          agent.step(time_step, is_evaluation=True) for agent in agents\n",
        "      ]\n",
        "      action_list = [agent_output.action for agent_output in agents_output]\n",
        "      print('action_list:', action_list)\n",
        "      raise\n",
        "      time_step = env.step(action_list)\n",
        "      episode_rewards += time_step.rewards\n",
        "    sum_episode_rewards += episode_rewards\n",
        "    if verbose:\n",
        "      print(f\"Finished episode {ep}, \"\n",
        "            + f\"avg returns: {sum_episode_rewards / (ep+1)}\")\n",
        "\n",
        "  return sum_episode_rewards / num_episodes\n",
        "\n",
        "\n",
        "def print_roshambo_bot_names_and_ids(roshambo_bot_names):\n",
        "  print(\"Roshambo bot population:\")\n",
        "  for i in range(len(roshambo_bot_names)):\n",
        "    print(f\"{i}: {roshambo_bot_names[i]}\")\n",
        "\n",
        "def create_roshambo_bot_agent(player_id, num_actions, bot_names, pop_id):\n",
        "  name = bot_names[pop_id]\n",
        "  # Creates an OpenSpiel bot with the default number of throws\n",
        "  # (pyspiel.ROSHAMBO_NUM_THROWS). To create one for a different number of\n",
        "  # throws per episode, add the number as the third argument here.\n",
        "  bot = pyspiel.make_roshambo_bot(player_id, name)\n",
        "  return BotAgent(num_actions, bot, name=name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VnGvjA17ncW",
        "outputId": "733ca6ed-de85-4be0-d5e2-c57f61a603a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading bot population...\n",
            "Population size: 43\n",
            "Roshambo bot population:\n",
            "0: actr_lag2_decay\n",
            "1: adddriftbot2\n",
            "2: addshiftbot3\n",
            "3: antiflatbot\n",
            "4: antirotnbot\n",
            "5: biopic\n",
            "6: boom\n",
            "7: copybot\n",
            "8: debruijn81\n",
            "9: driftbot\n",
            "10: flatbot3\n",
            "11: foxtrotbot\n",
            "12: freqbot2\n",
            "13: granite\n",
            "14: greenberg\n",
            "15: halbot\n",
            "16: inocencio\n",
            "17: iocainebot\n",
            "18: marble\n",
            "19: markov5\n",
            "20: markovbails\n",
            "21: mixed_strategy\n",
            "22: mod1bot\n",
            "23: multibot\n",
            "24: peterbot\n",
            "25: phasenbott\n",
            "26: pibot\n",
            "27: piedra\n",
            "28: predbot\n",
            "29: r226bot\n",
            "30: randbot\n",
            "31: robertot\n",
            "32: rockbot\n",
            "33: rotatebot\n",
            "34: russrocker4\n",
            "35: shofar\n",
            "36: sunCrazybot\n",
            "37: sunNervebot\n",
            "38: sweetrock\n",
            "39: switchalot\n",
            "40: switchbot\n",
            "41: textbot\n",
            "42: zq_move\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading bot population...\")\n",
        "pop_size = pyspiel.ROSHAMBO_NUM_BOTS\n",
        "print(f\"Population size: {pop_size}\")\n",
        "roshambo_bot_names = pyspiel.roshambo_bot_names()\n",
        "roshambo_bot_names.sort()\n",
        "print_roshambo_bot_names_and_ids(roshambo_bot_names)\n",
        "\n",
        "bot_id = 0\n",
        "roshambo_bot_ids = {}\n",
        "for name in roshambo_bot_names:\n",
        "  roshambo_bot_ids[name] = bot_id\n",
        "  bot_id += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "pAp1mEkj-LFq",
        "outputId": "0abf3909-61b2-4b16-bb39-1b7b2b61de95"
      },
      "outputs": [],
      "source": [
        "# # Example: create an RL environment, and two agents from the bot population and\n",
        "# # evaluate these two agents head-to-head.\n",
        "\n",
        "# # Note that the include_full_state variable has to be enabled because the\n",
        "# # BotAgent needs access to the full state.\n",
        "# env = rl_environment.Environment(\n",
        "#     \"repeated_game(stage_game=matrix_rps(),num_repetitions=\" +\n",
        "#     f\"{pyspiel.ROSHAMBO_NUM_THROWS},\" +\n",
        "#     f\"recall={RECALL})\",\n",
        "#     include_full_state=True)\n",
        "# num_players = 2\n",
        "# num_actions = env.action_spec()[\"num_actions\"]\n",
        "# # Learning agents might need this:\n",
        "# # info_state_size = env.observation_spec()[\"info_state\"][0]\n",
        "\n",
        "# # Create two bot agents\n",
        "# p0_pop_id = 0   # actr_lag2_decay\n",
        "# p1_pop_id = 1   # adddriftbot2\n",
        "# agents = [\n",
        "#     create_roshambo_bot_agent(0, num_actions, roshambo_bot_names, p0_pop_id),\n",
        "#     create_roshambo_bot_agent(1, num_actions, roshambo_bot_names, p1_pop_id)\n",
        "# ]\n",
        "\n",
        "# print(\"Starting eval run.\")\n",
        "# avg_eval_returns = eval_agents(env, agents, num_players, 10, verbose=True)\n",
        "\n",
        "# print(\"Avg return \", avg_eval_returns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ0coh6N8TZV"
      },
      "source": [
        "# My own code\n",
        "\n",
        "Altered or completely new code. Used to generate training data for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oLoUto7V8Utv"
      },
      "outputs": [],
      "source": [
        "RECALL = 20\n",
        "env = rl_environment.Environment(\n",
        "    \"repeated_game(stage_game=matrix_rps(),num_repetitions=\" +\n",
        "    f\"{pyspiel.ROSHAMBO_NUM_THROWS},\" +\n",
        "    f\"recall={RECALL})\",\n",
        "    include_full_state=True)\n",
        "num_players = 2\n",
        "num_actions = env.action_spec()[\"num_actions\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "a_DRLdJ_71gd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from open_spiel.python import rl_environment\n",
        "import pyspiel\n",
        "\n",
        "# Import your helpers (names may differ in your codebase)\n",
        "# from roshambo_population import create_roshambo_bot_agent, roshambo_bot_names\n",
        "# from my_random_agent import RandomAgent  # or any simple baseline agent\n",
        "\n",
        "class MyAgent(rl_agent.AbstractAgent):\n",
        "    \"\"\"\n",
        "    Greenberg-lite ensemble agent for repeated RPS:\n",
        "\n",
        "    - Maintains several simple \"expert\" strategies (predictors + best-response).\n",
        "    - Tracks a score for each expert based on how well it *would have* done.\n",
        "    - At each step, picks the action of the best-scoring expert (with some\n",
        "      epsilon exploration).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 player_id,\n",
        "                 num_actions=3,\n",
        "                 score_alpha=0.1,      # how fast expert scores update\n",
        "                 epsilon_action=0.1,  # randomization over actions\n",
        "                 epsilon_expert=0.05,  # randomization over experts\n",
        "                 name=\"ensemble_agent\"\n",
        "                #  lstm_model_path=\"lstm_rps.pt\",\n",
        "                 ):\n",
        "        super().__init__(player_id=player_id, name=name)\n",
        "        assert num_actions == 3, \"RRPS uses 3 actions (R,P,S).\"\n",
        "        self._player_id = player_id\n",
        "        self._num_actions = num_actions\n",
        "\n",
        "        self._score_alpha = score_alpha\n",
        "        self._eps_action = epsilon_action\n",
        "        self._eps_expert = epsilon_expert\n",
        "\n",
        "        # Payoff matrix from *my* perspective\n",
        "        # rows = my action, cols = opponent action\n",
        "        # 0: Rock, 1: Paper, 2: Scissors\n",
        "        self._payoff = np.array([\n",
        "            [ 0, -1,  1],  # I play R\n",
        "            [ 1,  0, -1],  # I play P\n",
        "            [-1,  1,  0],  # I play S\n",
        "        ], dtype=float)\n",
        "\n",
        "        # Number of experts we'll define\n",
        "        self._num_experts = 4  # you can add more if you want\n",
        "        # self._lstm_seq_len = lstm_seq_len\n",
        "        # self._device = torch.device(\"cpu\")  # or \"cuda\" if allowed\n",
        "        # self._lstm_model = torch.load(lstm_model_path, map_location=self._device)\n",
        "        # self._lstm_model.eval()\n",
        "        # self._lstm_hidden = None\n",
        "\n",
        "        self.restart()\n",
        "\n",
        "    # ------------ Episode reset ------------\n",
        "\n",
        "    def restart(self):\n",
        "        # Opponent statistics\n",
        "        self._opp_counts = np.ones(self._num_actions, dtype=float)  # smoothed counts\n",
        "        self._trans_counts = np.ones((self._num_actions, self._num_actions),\n",
        "                                     dtype=float)  # P(opp_t | opp_{t-1})\n",
        "\n",
        "        self._last_opp_action = None\n",
        "        self._last_my_action = None\n",
        "\n",
        "        # Expert scores and last actions they recommended\n",
        "        self._expert_scores = np.zeros(self._num_experts, dtype=float)\n",
        "        self._last_expert_actions = [None] * self._num_experts\n",
        "\n",
        "        # Track how much of history we've processed (if we use it later)\n",
        "        self._last_history_len = 0\n",
        "\n",
        "        # self._opp_hist = []\n",
        "        # self._lstm_hidden = None\n",
        "\n",
        "    # ------------ Utility helpers ------------\n",
        "\n",
        "    def _beat(self, move):\n",
        "        #Return the action that beats 'move'\n",
        "        if move is None:\n",
        "            return np.random.randint(self._num_actions)\n",
        "        return (move + 1) % self._num_actions\n",
        "\n",
        "    def _update_opp_stats(self, state):\n",
        "        #Update opponent statistics based on game history.\n",
        "        history = state.history()\n",
        "        if len(history) == 0:\n",
        "            return None\n",
        "\n",
        "        action = history[-1]\n",
        "        # Update counts\n",
        "        self._opp_counts[action] += 1\n",
        "        if self._last_opp_action is not None:\n",
        "            self._trans_counts[self._last_opp_action, action] += 1\n",
        "        self._last_opp_action = action\n",
        "        # self._opp_hist.append(action)\n",
        "        return action\n",
        "    \n",
        "\n",
        "    # ------------ Expert strategies ------------\n",
        "\n",
        "    def _expert_actions(self):\n",
        "        #Compute each expert's recommended action for step.\n",
        "        actions = []\n",
        "\n",
        "        # Expert 0: Frequency-based best response\n",
        "        # Predict opp's most frequent move overall.\n",
        "        opp_probs = self._opp_counts / np.sum(self._opp_counts)\n",
        "        pred0 = int(np.argmax(opp_probs))\n",
        "        actions.append(self._beat(pred0))\n",
        "\n",
        "        # Expert 1: Last-opponent-move best response\n",
        "        # Predict they repeat their last move.\n",
        "        actions.append(self._beat(self._last_opp_action))\n",
        "\n",
        "        # Expert 2: Markov(1) best response\n",
        "        # Predict based on last opp move -> next opp move.\n",
        "        if self._last_opp_action is not None:\n",
        "            row = self._trans_counts[self._last_opp_action]\n",
        "            pred2 = int(np.argmax(row))\n",
        "            actions.append(self._beat(pred2))\n",
        "        else:\n",
        "            # fallback to frequency BR\n",
        "            actions.append(self._beat(pred0))\n",
        "\n",
        "        # Expert 3: Mirror-me assumption\n",
        "        # Predict opp plays what I played last time.\n",
        "        actions.append(self._beat(self._last_my_action))\n",
        "\n",
        "        # # Expert 4: ML (LSTM)\n",
        "        # pred_lstm = self._lstm_predict_opp()\n",
        "        # if pred_lstm is not None:\n",
        "        #     actions.append(self._beat(pred_lstm))\n",
        "        # else:\n",
        "        #     # fallback: behave like frequency BR\n",
        "        #     actions.append(self._beat(pred0))\n",
        "\n",
        "\n",
        "        return actions\n",
        "\n",
        "    # ------------ Expert scoring ------------\n",
        "\n",
        "    def _update_expert_scores(self, last_opp_action):\n",
        "        \"\"\"\n",
        "        Update each expert's score based on what happened in the *previous* round.\n",
        "\n",
        "        We use the payoff matrix: if expert i had played its suggested action,\n",
        "        what reward would it have gotten vs last_opp_action?\n",
        "        \"\"\"\n",
        "        if last_opp_action is None:\n",
        "            return  # nothing to update on the first move\n",
        "\n",
        "        for i in range(self._num_experts):\n",
        "            a_i = self._last_expert_actions[i]\n",
        "            if a_i is None:\n",
        "                continue\n",
        "            payoff_i = self._payoff[a_i, last_opp_action]\n",
        "            # Exponential moving average of payoff\n",
        "            self._expert_scores[i] = (\n",
        "                (1 - self._score_alpha) * self._expert_scores[i]\n",
        "                + self._score_alpha * payoff_i\n",
        "            )\n",
        "\n",
        "    # ------------ Main step ------------\n",
        "\n",
        "    def step(self, time_step, is_evaluation=False):\n",
        "        # Terminal: return dummy\n",
        "        if time_step.last():\n",
        "            probs = np.ones(self._num_actions) / self._num_actions\n",
        "            return rl_agent.StepOutput(action=0, probs=probs)\n",
        "\n",
        "        # Deserialize game state\n",
        "        game, state = pyspiel.deserialize_game_and_state(\n",
        "            time_step.observations[\"serialized_state\"])\n",
        "\n",
        "        # 1) Update opponent stats (includes last_opp_action)\n",
        "        last_opp_action = self._update_opp_stats(state)\n",
        "\n",
        "        # 2) Update expert scores based on previous round outcome\n",
        "        # We don't need time_step.rewards here; we recompute payoff from matrix.\n",
        "        self._update_expert_scores(last_opp_action)\n",
        "\n",
        "        # 3) Each expert proposes an action for THIS round\n",
        "        expert_actions = self._expert_actions()\n",
        "        self._last_expert_actions = list(expert_actions)  # store for next scoring\n",
        "\n",
        "        # 4) Choose which expert to follow (epsilon-greedy over expert scores)\n",
        "        if np.random.rand() < self._eps_expert:\n",
        "            chosen_expert = np.random.randint(self._num_experts)\n",
        "        else:\n",
        "            chosen_expert = int(np.argmax(self._expert_scores))\n",
        "\n",
        "        chosen_action = expert_actions[chosen_expert]\n",
        "\n",
        "        # 5) Add action-level randomness for robustness\n",
        "        if np.random.rand() < self._eps_action:\n",
        "            action = np.random.randint(self._num_actions)\n",
        "        else:\n",
        "            action = chosen_action\n",
        "\n",
        "        # Save my last action for next round's mirror expert\n",
        "        self._last_my_action = action\n",
        "\n",
        "        # 6) Build probability distribution (mostly on chosen_action)\n",
        "        probs = np.ones(self._num_actions) * (self._eps_action / self._num_actions)\n",
        "        probs[chosen_action] += 1.0 - self._eps_action\n",
        "\n",
        "        return rl_agent.StepOutput(action=action, probs=probs)\n",
        "    \n",
        "\n",
        "\n",
        "def generate_rrps_data(\n",
        "    roshambo_bot_names,\n",
        "    create_roshambo_bot_agent,\n",
        "    num_episodes_per_bot=50,\n",
        "    horizon=1000,\n",
        "    output_path=\"rrps_lstm_data.npz\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate training data for an LSTM that predicts opponent moves.\n",
        "\n",
        "    For each bot in the population:\n",
        "      - Play num_episodes_per_bot episodes\n",
        "      - Each episode has up to `horizon` steps (num_repetitions)\n",
        "      - Record the sequence of opponent actions (0=R,1=P,2=S)\n",
        "\n",
        "    Saves a .npz file with:\n",
        "      - episodes: list of lists of ints (opponent moves)\n",
        "      - bot_ids:  list of int bot indices (aligned with episodes)\n",
        "      - bot_names: list of strings (names for reference)\n",
        "    \"\"\"\n",
        "\n",
        "    # ----- Build the repeated RPS game -----\n",
        "    # Adjust if your game is constructed differently.\n",
        "    # game = pyspiel.load_game(\n",
        "    #     \"repeated_game\",\n",
        "    #     {\n",
        "    #         \"num_repetitions\": horizon,\n",
        "    #         \"stage_game\": \"matrix_rps\",\n",
        "    #     },\n",
        "    # )\n",
        "    # env = rl_environment.Environment(game)\n",
        "\n",
        "    env = rl_environment.Environment(\n",
        "    \"repeated_game(stage_game=matrix_rps(),num_repetitions=\" +\n",
        "    f\"{pyspiel.ROSHAMBO_NUM_THROWS},\" +\n",
        "    f\"recall={RECALL})\",\n",
        "    include_full_state=True)\n",
        "\n",
        "    num_actions = 3\n",
        "    num_players = 2\n",
        "\n",
        "    all_episodes = []\n",
        "    all_bot_ids = []\n",
        "\n",
        "    for bot_id, bot_name in enumerate(roshambo_bot_names):\n",
        "        print(f\"Collecting data vs bot {bot_id}: {bot_name}\")\n",
        "\n",
        "\n",
        "        class UniformAgent:\n",
        "            def __init__(self, player_id, num_actions=3):\n",
        "                self.player_id = player_id\n",
        "                self.num_actions = num_actions\n",
        "            def restart(self):\n",
        "                pass\n",
        "            def step(self, time_step, is_evaluation=False):\n",
        "                if time_step.last():\n",
        "                    # Dummy output, env ignores action at terminal\n",
        "                    return type(\"Out\", (), {\"action\": 0})\n",
        "                a = np.random.randint(self.num_actions)\n",
        "                return type(\"Out\", (), {\"action\": int(a)})\n",
        "\n",
        "        my_agent = MyAgent(player_id=0, num_actions=num_actions)\n",
        "        # my_agent = create_roshambo_bot_agent(\n",
        "        #     player_id=0,\n",
        "        #     num_actions=num_actions,\n",
        "        #     roshambo_bot_names=roshambo_bot_names,\n",
        "        #     roshambo_bot_index=bot_id,\n",
        "        # )\n",
        "        opp_agent = create_roshambo_bot_agent(\n",
        "            1,\n",
        "            num_actions,\n",
        "            roshambo_bot_names,\n",
        "            bot_id,\n",
        "        )\n",
        "\n",
        "        for ep in range(num_episodes_per_bot):\n",
        "            # Restart agents if they support it\n",
        "            if hasattr(my_agent, \"restart\"):\n",
        "                my_agent.restart()\n",
        "            if hasattr(opp_agent, \"restart\"):\n",
        "                opp_agent.restart()\n",
        "\n",
        "            time_step = env.reset()\n",
        "            opp_actions = []\n",
        "\n",
        "            while not time_step.last():\n",
        "                # Collect actions from both players\n",
        "                outputs = [\n",
        "                    my_agent.step(time_step, is_evaluation=True),\n",
        "                    opp_agent.step(time_step, is_evaluation=True),\n",
        "                ]\n",
        "                action_list = [out.action for out in outputs]\n",
        "\n",
        "                # Here we assume my_agent is player 0, opp_agent is player 1:\n",
        "                opp_action = action_list[1]\n",
        "                opp_actions.append(int(opp_action))\n",
        "\n",
        "                # Step environment\n",
        "                time_step = env.step(action_list)\n",
        "\n",
        "            all_episodes.append(opp_actions)\n",
        "            all_bot_ids.append(bot_id)\n",
        "\n",
        "            if (ep + 1) % 10 == 0:\n",
        "                print(f\"  Bot {bot_name}: episode {ep+1}/{num_episodes_per_bot}\")\n",
        "\n",
        "    # Save as a numpy object array (list-of-lists) plus labels.\n",
        "    episodes_arr = np.array(all_episodes, dtype=object)\n",
        "    bot_ids_arr = np.array(all_bot_ids, dtype=np.int32)\n",
        "\n",
        "    np.savez(\n",
        "        output_path,\n",
        "        episodes=episodes_arr,\n",
        "        bot_ids=bot_ids_arr,\n",
        "        bot_names=np.array(roshambo_bot_names, dtype=object),\n",
        "    )\n",
        "    print(f\"Saved dataset to {output_path}\")\n",
        "\n",
        "\n",
        "# Example usage (adjust imports / names to your actual code):\n",
        "# from roshambo_population import create_roshambo_bot_agent, roshambo_bot_names\n",
        "# generate_rrps_data(roshambo_bot_names, create_roshambo_bot_agent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "M10WtF1lAEn2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting data vs bot 0: actr_lag2_decay\n",
            "  Bot actr_lag2_decay: episode 10/50\n",
            "  Bot actr_lag2_decay: episode 20/50\n",
            "  Bot actr_lag2_decay: episode 30/50\n",
            "  Bot actr_lag2_decay: episode 40/50\n",
            "  Bot actr_lag2_decay: episode 50/50\n",
            "Collecting data vs bot 1: adddriftbot2\n",
            "  Bot adddriftbot2: episode 10/50\n",
            "  Bot adddriftbot2: episode 20/50\n",
            "  Bot adddriftbot2: episode 30/50\n",
            "  Bot adddriftbot2: episode 40/50\n",
            "  Bot adddriftbot2: episode 50/50\n",
            "Collecting data vs bot 2: addshiftbot3\n",
            "  Bot addshiftbot3: episode 10/50\n",
            "  Bot addshiftbot3: episode 20/50\n",
            "  Bot addshiftbot3: episode 30/50\n",
            "  Bot addshiftbot3: episode 40/50\n",
            "  Bot addshiftbot3: episode 50/50\n",
            "Collecting data vs bot 3: antiflatbot\n",
            "  Bot antiflatbot: episode 10/50\n",
            "  Bot antiflatbot: episode 20/50\n",
            "  Bot antiflatbot: episode 30/50\n",
            "  Bot antiflatbot: episode 40/50\n",
            "  Bot antiflatbot: episode 50/50\n",
            "Collecting data vs bot 4: antirotnbot\n",
            "  Bot antirotnbot: episode 10/50\n",
            "  Bot antirotnbot: episode 20/50\n",
            "  Bot antirotnbot: episode 30/50\n",
            "  Bot antirotnbot: episode 40/50\n",
            "  Bot antirotnbot: episode 50/50\n",
            "Collecting data vs bot 5: biopic\n",
            "  Bot biopic: episode 10/50\n",
            "  Bot biopic: episode 20/50\n",
            "  Bot biopic: episode 30/50\n",
            "  Bot biopic: episode 40/50\n",
            "  Bot biopic: episode 50/50\n",
            "Collecting data vs bot 6: boom\n",
            "  Bot boom: episode 10/50\n",
            "  Bot boom: episode 20/50\n",
            "  Bot boom: episode 30/50\n",
            "  Bot boom: episode 40/50\n",
            "  Bot boom: episode 50/50\n",
            "Collecting data vs bot 7: copybot\n",
            "  Bot copybot: episode 10/50\n",
            "  Bot copybot: episode 20/50\n",
            "  Bot copybot: episode 30/50\n",
            "  Bot copybot: episode 40/50\n",
            "  Bot copybot: episode 50/50\n",
            "Collecting data vs bot 8: debruijn81\n",
            "  Bot debruijn81: episode 10/50\n",
            "  Bot debruijn81: episode 20/50\n",
            "  Bot debruijn81: episode 30/50\n",
            "  Bot debruijn81: episode 40/50\n",
            "  Bot debruijn81: episode 50/50\n",
            "Collecting data vs bot 9: driftbot\n",
            "  Bot driftbot: episode 10/50\n",
            "  Bot driftbot: episode 20/50\n",
            "  Bot driftbot: episode 30/50\n",
            "  Bot driftbot: episode 40/50\n",
            "  Bot driftbot: episode 50/50\n",
            "Collecting data vs bot 10: flatbot3\n",
            "  Bot flatbot3: episode 10/50\n",
            "  Bot flatbot3: episode 20/50\n",
            "  Bot flatbot3: episode 30/50\n",
            "  Bot flatbot3: episode 40/50\n",
            "  Bot flatbot3: episode 50/50\n",
            "Collecting data vs bot 11: foxtrotbot\n",
            "  Bot foxtrotbot: episode 10/50\n",
            "  Bot foxtrotbot: episode 20/50\n",
            "  Bot foxtrotbot: episode 30/50\n",
            "  Bot foxtrotbot: episode 40/50\n",
            "  Bot foxtrotbot: episode 50/50\n",
            "Collecting data vs bot 12: freqbot2\n",
            "  Bot freqbot2: episode 10/50\n",
            "  Bot freqbot2: episode 20/50\n",
            "  Bot freqbot2: episode 30/50\n",
            "  Bot freqbot2: episode 40/50\n",
            "  Bot freqbot2: episode 50/50\n",
            "Collecting data vs bot 13: granite\n",
            "  Bot granite: episode 10/50\n",
            "  Bot granite: episode 20/50\n",
            "  Bot granite: episode 30/50\n",
            "  Bot granite: episode 40/50\n",
            "  Bot granite: episode 50/50\n",
            "Collecting data vs bot 14: greenberg\n",
            "  Bot greenberg: episode 10/50\n",
            "  Bot greenberg: episode 20/50\n",
            "  Bot greenberg: episode 30/50\n",
            "  Bot greenberg: episode 40/50\n",
            "  Bot greenberg: episode 50/50\n",
            "Collecting data vs bot 15: halbot\n",
            "  Bot halbot: episode 10/50\n",
            "  Bot halbot: episode 20/50\n",
            "  Bot halbot: episode 30/50\n",
            "  Bot halbot: episode 40/50\n",
            "  Bot halbot: episode 50/50\n",
            "Collecting data vs bot 16: inocencio\n",
            "  Bot inocencio: episode 10/50\n",
            "  Bot inocencio: episode 20/50\n",
            "  Bot inocencio: episode 30/50\n",
            "  Bot inocencio: episode 40/50\n",
            "  Bot inocencio: episode 50/50\n",
            "Collecting data vs bot 17: iocainebot\n",
            "  Bot iocainebot: episode 10/50\n",
            "  Bot iocainebot: episode 20/50\n",
            "  Bot iocainebot: episode 30/50\n",
            "  Bot iocainebot: episode 40/50\n",
            "  Bot iocainebot: episode 50/50\n",
            "Collecting data vs bot 18: marble\n",
            "  Bot marble: episode 10/50\n",
            "  Bot marble: episode 20/50\n",
            "  Bot marble: episode 30/50\n",
            "  Bot marble: episode 40/50\n",
            "  Bot marble: episode 50/50\n",
            "Collecting data vs bot 19: markov5\n",
            "  Bot markov5: episode 10/50\n",
            "  Bot markov5: episode 20/50\n",
            "  Bot markov5: episode 30/50\n",
            "  Bot markov5: episode 40/50\n",
            "  Bot markov5: episode 50/50\n",
            "Collecting data vs bot 20: markovbails\n",
            "  Bot markovbails: episode 10/50\n",
            "  Bot markovbails: episode 20/50\n",
            "  Bot markovbails: episode 30/50\n",
            "  Bot markovbails: episode 40/50\n",
            "  Bot markovbails: episode 50/50\n",
            "Collecting data vs bot 21: mixed_strategy\n",
            "  Bot mixed_strategy: episode 10/50\n",
            "  Bot mixed_strategy: episode 20/50\n",
            "  Bot mixed_strategy: episode 30/50\n",
            "  Bot mixed_strategy: episode 40/50\n",
            "  Bot mixed_strategy: episode 50/50\n",
            "Collecting data vs bot 22: mod1bot\n",
            "  Bot mod1bot: episode 10/50\n",
            "  Bot mod1bot: episode 20/50\n",
            "  Bot mod1bot: episode 30/50\n",
            "  Bot mod1bot: episode 40/50\n",
            "  Bot mod1bot: episode 50/50\n",
            "Collecting data vs bot 23: multibot\n",
            "  Bot multibot: episode 10/50\n",
            "  Bot multibot: episode 20/50\n",
            "  Bot multibot: episode 30/50\n",
            "  Bot multibot: episode 40/50\n",
            "  Bot multibot: episode 50/50\n",
            "Collecting data vs bot 24: peterbot\n",
            "  Bot peterbot: episode 10/50\n",
            "  Bot peterbot: episode 20/50\n",
            "  Bot peterbot: episode 30/50\n",
            "  Bot peterbot: episode 40/50\n",
            "  Bot peterbot: episode 50/50\n",
            "Collecting data vs bot 25: phasenbott\n",
            "  Bot phasenbott: episode 10/50\n",
            "  Bot phasenbott: episode 20/50\n",
            "  Bot phasenbott: episode 30/50\n",
            "  Bot phasenbott: episode 40/50\n",
            "  Bot phasenbott: episode 50/50\n",
            "Collecting data vs bot 26: pibot\n",
            "  Bot pibot: episode 10/50\n",
            "  Bot pibot: episode 20/50\n",
            "  Bot pibot: episode 30/50\n",
            "  Bot pibot: episode 40/50\n",
            "  Bot pibot: episode 50/50\n",
            "Collecting data vs bot 27: piedra\n",
            "  Bot piedra: episode 10/50\n",
            "  Bot piedra: episode 20/50\n",
            "  Bot piedra: episode 30/50\n",
            "  Bot piedra: episode 40/50\n",
            "  Bot piedra: episode 50/50\n",
            "Collecting data vs bot 28: predbot\n",
            "  Bot predbot: episode 10/50\n",
            "  Bot predbot: episode 20/50\n",
            "  Bot predbot: episode 30/50\n",
            "  Bot predbot: episode 40/50\n",
            "  Bot predbot: episode 50/50\n",
            "Collecting data vs bot 29: r226bot\n",
            "  Bot r226bot: episode 10/50\n",
            "  Bot r226bot: episode 20/50\n",
            "  Bot r226bot: episode 30/50\n",
            "  Bot r226bot: episode 40/50\n",
            "  Bot r226bot: episode 50/50\n",
            "Collecting data vs bot 30: randbot\n",
            "  Bot randbot: episode 10/50\n",
            "  Bot randbot: episode 20/50\n",
            "  Bot randbot: episode 30/50\n",
            "  Bot randbot: episode 40/50\n",
            "  Bot randbot: episode 50/50\n",
            "Collecting data vs bot 31: robertot\n",
            "  Bot robertot: episode 10/50\n",
            "  Bot robertot: episode 20/50\n",
            "  Bot robertot: episode 30/50\n",
            "  Bot robertot: episode 40/50\n",
            "  Bot robertot: episode 50/50\n",
            "Collecting data vs bot 32: rockbot\n",
            "  Bot rockbot: episode 10/50\n",
            "  Bot rockbot: episode 20/50\n",
            "  Bot rockbot: episode 30/50\n",
            "  Bot rockbot: episode 40/50\n",
            "  Bot rockbot: episode 50/50\n",
            "Collecting data vs bot 33: rotatebot\n",
            "  Bot rotatebot: episode 10/50\n",
            "  Bot rotatebot: episode 20/50\n",
            "  Bot rotatebot: episode 30/50\n",
            "  Bot rotatebot: episode 40/50\n",
            "  Bot rotatebot: episode 50/50\n",
            "Collecting data vs bot 34: russrocker4\n",
            "  Bot russrocker4: episode 10/50\n",
            "  Bot russrocker4: episode 20/50\n",
            "  Bot russrocker4: episode 30/50\n",
            "  Bot russrocker4: episode 40/50\n",
            "  Bot russrocker4: episode 50/50\n",
            "Collecting data vs bot 35: shofar\n",
            "  Bot shofar: episode 10/50\n",
            "  Bot shofar: episode 20/50\n",
            "  Bot shofar: episode 30/50\n",
            "  Bot shofar: episode 40/50\n",
            "  Bot shofar: episode 50/50\n",
            "Collecting data vs bot 36: sunCrazybot\n",
            "  Bot sunCrazybot: episode 10/50\n",
            "  Bot sunCrazybot: episode 20/50\n",
            "  Bot sunCrazybot: episode 30/50\n",
            "  Bot sunCrazybot: episode 40/50\n",
            "  Bot sunCrazybot: episode 50/50\n",
            "Collecting data vs bot 37: sunNervebot\n",
            "  Bot sunNervebot: episode 10/50\n",
            "  Bot sunNervebot: episode 20/50\n",
            "  Bot sunNervebot: episode 30/50\n",
            "  Bot sunNervebot: episode 40/50\n",
            "  Bot sunNervebot: episode 50/50\n",
            "Collecting data vs bot 38: sweetrock\n",
            "  Bot sweetrock: episode 10/50\n",
            "  Bot sweetrock: episode 20/50\n",
            "  Bot sweetrock: episode 30/50\n",
            "  Bot sweetrock: episode 40/50\n",
            "  Bot sweetrock: episode 50/50\n",
            "Collecting data vs bot 39: switchalot\n",
            "  Bot switchalot: episode 10/50\n",
            "  Bot switchalot: episode 20/50\n",
            "  Bot switchalot: episode 30/50\n",
            "  Bot switchalot: episode 40/50\n",
            "  Bot switchalot: episode 50/50\n",
            "Collecting data vs bot 40: switchbot\n",
            "  Bot switchbot: episode 10/50\n",
            "  Bot switchbot: episode 20/50\n",
            "  Bot switchbot: episode 30/50\n",
            "  Bot switchbot: episode 40/50\n",
            "  Bot switchbot: episode 50/50\n",
            "Collecting data vs bot 41: textbot\n",
            "  Bot textbot: episode 10/50\n",
            "  Bot textbot: episode 20/50\n",
            "  Bot textbot: episode 30/50\n",
            "  Bot textbot: episode 40/50\n",
            "  Bot textbot: episode 50/50\n",
            "Collecting data vs bot 42: zq_move\n",
            "  Bot zq_move: episode 10/50\n",
            "  Bot zq_move: episode 20/50\n",
            "  Bot zq_move: episode 30/50\n",
            "  Bot zq_move: episode 40/50\n",
            "  Bot zq_move: episode 50/50\n",
            "Saved dataset to rrps_lstm_data.npz\n"
          ]
        }
      ],
      "source": [
        "generate_rrps_data(roshambo_bot_names, create_roshambo_bot_agent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keys: ['episodes', 'bot_ids', 'bot_names']\n",
            "episodes dtype: object\n",
            "num episodes: 2150\n",
            "bot_ids shape: (2150,)\n",
            "bot_names: ['actr_lag2_decay' 'adddriftbot2' 'addshiftbot3' 'antiflatbot'\n",
            " 'antirotnbot' 'biopic' 'boom' 'copybot' 'debruijn81' 'driftbot'\n",
            " 'flatbot3' 'foxtrotbot' 'freqbot2' 'granite' 'greenberg' 'halbot'\n",
            " 'inocencio' 'iocainebot' 'marble' 'markov5' 'markovbails'\n",
            " 'mixed_strategy' 'mod1bot' 'multibot' 'peterbot' 'phasenbott' 'pibot'\n",
            " 'piedra' 'predbot' 'r226bot' 'randbot' 'robertot' 'rockbot' 'rotatebot'\n",
            " 'russrocker4' 'shofar' 'sunCrazybot' 'sunNervebot' 'sweetrock'\n",
            " 'switchalot' 'switchbot' 'textbot' 'zq_move']\n",
            "\n",
            "Episode 0, bot_id=0:\n",
            "length: 1000\n",
            "moves: [0 1 1 0 1 1 1 2 2 0 1 0 1 0 1 0 0 1 1 0] ...\n",
            "\n",
            "Episode 1, bot_id=0:\n",
            "length: 1000\n",
            "moves: [1 0 0 2 2 2 2 0 0 1 2 2 0 2 2 2 1 2 0 0] ...\n",
            "\n",
            "Episode 2, bot_id=0:\n",
            "length: 1000\n",
            "moves: [1 2 2 2 0 1 0 1 0 0 2 0 1 2 1 0 2 1 1 2] ...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.load(\"rrps_lstm_data.npz\", allow_pickle=True)\n",
        "print(\"Keys:\", data.files)\n",
        "\n",
        "episodes = data[\"episodes\"]\n",
        "bot_ids = data[\"bot_ids\"]\n",
        "bot_names = data[\"bot_names\"]\n",
        "\n",
        "print(\"episodes dtype:\", episodes.dtype)\n",
        "print(\"num episodes:\", len(episodes))\n",
        "print(\"bot_ids shape:\", bot_ids.shape)\n",
        "print(\"bot_names:\", bot_names)\n",
        "\n",
        "# Peek at first few episodes\n",
        "for i in range(min(3, len(episodes))):\n",
        "    print(f\"\\nEpisode {i}, bot_id={bot_ids[i]}:\")\n",
        "    print(\"length:\", len(episodes[i]))\n",
        "    print(\"moves:\", episodes[i][:20], \"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lZzSaIfjaiF"
      },
      "source": [
        "The below cell is used to generate training data. It runs games with one specific bot (in this case Greenberg) against randbot. This data was used to train the first iteration of the model (the one focused purely on beating Greenberg)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZN9Tb-0h_DfY"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'myAgent' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m trainBot = BotAgent(num_actions, pyspiel.make_roshambo_bot(\u001b[32m0\u001b[39m, botName), name=botName)  \u001b[38;5;66;03m# Bot for whom train data being generated\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# randBot = BotAgent(num_actions, pyspiel.make_roshambo_bot(1, 'randbot'), name='randbot')\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m randBot = \u001b[43mmyAgent\u001b[49m\n\u001b[32m     18\u001b[39m agents = [trainBot, randBot]\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Note: data is generated/saved in sets to avoid losing data if Colab kicks me off\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# With these numbers, each set takes ~3.5 mins (~2.1 sec/run)\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'myAgent' is not defined"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Generate training data for specified bot\n",
        "botName = 'greenberg'\n",
        "botId = roshambo_bot_ids[botName]\n",
        "\n",
        "env = rl_environment.Environment(\n",
        "    \"repeated_game(stage_game=matrix_rps(),num_repetitions=\" +\n",
        "    f\"{pyspiel.ROSHAMBO_NUM_THROWS},\" +\n",
        "    f\"recall={RECALL})\",\n",
        "    include_full_state=True)\n",
        "num_players = 2\n",
        "num_actions = env.action_spec()[\"num_actions\"]\n",
        "\n",
        "trainBot = BotAgent(num_actions, pyspiel.make_roshambo_bot(0, botName), name=botName)  # Bot for whom train data being generated\n",
        "# randBot = BotAgent(num_actions, pyspiel.make_roshambo_bot(1, 'randbot'), name='randbot')\n",
        "randBot = myAgent\n",
        "agents = [trainBot, randBot]\n",
        "\n",
        "# Note: data is generated/saved in sets to avoid losing data if Colab kicks me off\n",
        "# With these numbers, each set takes ~3.5 mins (~2.1 sec/run)\n",
        "numSets = 30   # Number of sets of data to generate\n",
        "numRuns = 100  # Number of runs to generate training data for per set\n",
        "\n",
        "for setNum in range(numSets):\n",
        "  runData = []  # Contains data for each run\n",
        "\n",
        "  for run in tqdm(range(numRuns), desc=f\"Set {setNum+1} / {numSets}\"):\n",
        "    # Reset variables for new run\n",
        "    randBot.restart()\n",
        "    trainBot.restart()\n",
        "    time_step = env.reset()\n",
        "\n",
        "    result = []  # Contains move data for this game\n",
        "\n",
        "    while not time_step.last():\n",
        "      actionList = [agent.step(time_step, is_evaluation=True).action for agent in agents]\n",
        "      result.append(actionList)\n",
        "      time_step = env.step(actionList)\n",
        "\n",
        "    runData.append(np.array(result, dtype=np.uint8))\n",
        "\n",
        "  if len(runData) != numRuns:\n",
        "    print(f\"Warning: length should be {numRuns} but is {len(runData)}\")\n",
        "\n",
        "  runData = np.array(runData, dtype=np.uint8)\n",
        "  print('Data shape:', runData.shape)\n",
        "\n",
        "  # Save np array containing results for this set to google drive\n",
        "  np.save(f'/content/drive/My Drive/CS486A4/Greenberg_data_LSTMv1/{botName}_{setNum}.npy', runData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0s0uLBbjlZz"
      },
      "source": [
        "The below cell is used to generate data. It runs games with one specific bot (in this case Greenberg) against every other bot. The data from this cell was not used in either of the models discussed in the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3T2btVTB02U"
      },
      "outputs": [],
      "source": [
        "# Unlike the above cell, this one focuses on generating data from different agents vs greenberg\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Generate training data for specified bot\n",
        "botName = 'greenberg'\n",
        "botId = roshambo_bot_ids[botName]\n",
        "\n",
        "# List of agents that always play same sequence of moves (so don't need to run them a lot)\n",
        "deterministic_agents = [\n",
        "    'rockbot', 'rotatebot', 'pibot', 'debruijn81', 'textbot'\n",
        "]\n",
        "\n",
        "env = rl_environment.Environment(\n",
        "    \"repeated_game(stage_game=matrix_rps(),num_repetitions=\" +\n",
        "    f\"{pyspiel.ROSHAMBO_NUM_THROWS},\" +\n",
        "    f\"recall={RECALL})\",\n",
        "    include_full_state=True)\n",
        "num_players = 2\n",
        "num_actions = env.action_spec()[\"num_actions\"]\n",
        "\n",
        "trainBot = BotAgent(num_actions, pyspiel.make_roshambo_bot(0, botName), name=botName)  # Bot for whom train data being generated\n",
        "# randBot = BotAgent(num_actions, pyspiel.make_roshambo_bot(1, 'randbot'), name='randbot')\n",
        "# agents = [trainBot, randBot]\n",
        "\n",
        "numRuns = 100  # Number of runs to generate training data for per model\n",
        "\n",
        "for name, id in roshambo_bot_ids.items():\n",
        "  runData = []  # Contains data for each run\n",
        "\n",
        "  dataBot = BotAgent(num_actions, pyspiel.make_roshambo_bot(1, name), name=name)\n",
        "  agents = [trainBot, dataBot]\n",
        "\n",
        "  # Run less times if this is a deterministic agent\n",
        "  runTimes = 5 if name in deterministic_agents else numRuns\n",
        "\n",
        "  for run in tqdm(range(runTimes), desc=f\"Agent {name} ({id + 1} / {len(roshambo_bot_names)})\"):\n",
        "    # Reset variables for new run\n",
        "    time_step = env.reset()\n",
        "    trainBot.restart()\n",
        "    if hasattr(dataBot, 'restart'):\n",
        "      dataBot.restart()\n",
        "\n",
        "    result = []  # Contains move data for this game\n",
        "\n",
        "    while not time_step.last():\n",
        "      actionList = [agent.step(time_step, is_evaluation=True).action for agent in agents]\n",
        "      result.append(actionList)\n",
        "      time_step = env.step(actionList)\n",
        "\n",
        "    runData.append(np.array(result, dtype=np.uint8))\n",
        "\n",
        "  if len(runData) != numRuns:\n",
        "    print(f\"Warning: length should be {numRuns} but is {len(runData)}\")\n",
        "\n",
        "  runData = np.array(runData, dtype=np.uint8)\n",
        "  print('Data shape:', runData.shape)\n",
        "\n",
        "  # Save np array containing results for this set to google drive\n",
        "  np.save(f'/content/drive/My Drive/Greenberg_AllBots_Data/{botName}-VS-{name}.npy', runData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AfB9YPej3q-"
      },
      "source": [
        "The below cell is used to generate data. It runs games with every bot against randbot. The data from this cell was used in the second model discussed in the report (the one that can be generalized to other models).\n",
        "\n",
        "This cell generates 150 games for each bot. If generating data on Colab, I recommend making 3 copies of this notebook and running all 3 at once to speed up data creation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6GIZMs8buTZ",
        "outputId": "af07e652-6e9a-473d-b847-d27f32212791"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent actr_lag2_decay (1 / 43): 100%|| 150/150 [04:50<00:00,  1.94s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent adddriftbot2 (2 / 43): 100%|| 150/150 [04:50<00:00,  1.94s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent addshiftbot3 (3 / 43): 100%|| 150/150 [04:51<00:00,  1.94s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent antiflatbot (4 / 43): 100%|| 150/150 [04:50<00:00,  1.94s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent antirotnbot (5 / 43): 100%|| 150/150 [04:51<00:00,  1.94s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent biopic (6 / 43): 100%|| 150/150 [04:55<00:00,  1.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent boom (7 / 43): 100%|| 150/150 [04:57<00:00,  1.98s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent copybot (8 / 43): 100%|| 150/150 [04:58<00:00,  1.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent debruijn81 (9 / 43): 100%|| 150/150 [04:55<00:00,  1.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent driftbot (10 / 43): 100%|| 150/150 [04:55<00:00,  1.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent flatbot3 (11 / 43): 100%|| 150/150 [04:54<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent foxtrotbot (12 / 43): 100%|| 150/150 [04:53<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent freqbot2 (13 / 43): 100%|| 150/150 [04:53<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent granite (14 / 43): 100%|| 150/150 [04:52<00:00,  1.95s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent greenberg (15 / 43): 100%|| 150/150 [05:17<00:00,  2.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent halbot (16 / 43): 100%|| 150/150 [05:02<00:00,  2.01s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent inocencio (17 / 43): 100%|| 150/150 [04:58<00:00,  1.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent iocainebot (18 / 43): 100%|| 150/150 [04:59<00:00,  2.00s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent marble (19 / 43): 100%|| 150/150 [04:54<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent markov5 (20 / 43): 100%|| 150/150 [04:54<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent markovbails (21 / 43): 100%|| 150/150 [04:54<00:00,  1.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent mixed_strategy (22 / 43): 100%|| 150/150 [04:54<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent mod1bot (23 / 43): 100%|| 150/150 [04:54<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent multibot (24 / 43): 100%|| 150/150 [04:55<00:00,  1.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent peterbot (25 / 43): 100%|| 150/150 [04:55<00:00,  1.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent phasenbott (26 / 43): 100%|| 150/150 [04:55<00:00,  1.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent pibot (27 / 43): 100%|| 150/150 [04:53<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent piedra (28 / 43): 100%|| 150/150 [04:53<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent predbot (29 / 43): 100%|| 150/150 [04:53<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent r226bot (30 / 43): 100%|| 150/150 [04:54<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent randbot (31 / 43): 100%|| 150/150 [04:53<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent robertot (32 / 43): 100%|| 150/150 [04:55<00:00,  1.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent rockbot (33 / 43): 100%|| 150/150 [04:57<00:00,  1.98s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent rotatebot (34 / 43): 100%|| 150/150 [04:56<00:00,  1.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent russrocker4 (35 / 43): 100%|| 150/150 [04:54<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent shofar (36 / 43): 100%|| 150/150 [04:56<00:00,  1.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent sunCrazybot (37 / 43): 100%|| 150/150 [04:54<00:00,  1.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent sunNervebot (38 / 43): 100%|| 150/150 [04:58<00:00,  1.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent sweetrock (39 / 43): 100%|| 150/150 [04:55<00:00,  1.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent switchalot (40 / 43): 100%|| 150/150 [04:54<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent switchbot (41 / 43): 100%|| 150/150 [04:54<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent textbot (42 / 43): 100%|| 150/150 [04:54<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Agent zq_move (43 / 43): 100%|| 150/150 [04:57<00:00,  1.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (150, 1000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Unlike the above cell, this one focuses on generating data from different agents vs randbot\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# List of agents that always play same sequence of moves (unused)\n",
        "deterministic_agents = [\n",
        "    'rockbot', 'rotatebot', 'pibot', 'debruijn81', 'textbot'\n",
        "]\n",
        "\n",
        "env = rl_environment.Environment(\n",
        "    \"repeated_game(stage_game=matrix_rps(),num_repetitions=\" +\n",
        "    f\"{pyspiel.ROSHAMBO_NUM_THROWS},\" +\n",
        "    f\"recall={RECALL})\",\n",
        "    include_full_state=True)\n",
        "num_players = 2\n",
        "num_actions = env.action_spec()[\"num_actions\"]\n",
        "\n",
        "# trainBot = BotAgent(num_actions, pyspiel.make_roshambo_bot(0, botName), name=botName)  # Bot for whom train data being generated\n",
        "randBot = BotAgent(num_actions, pyspiel.make_roshambo_bot(0, 'randbot'), name='randbot')\n",
        "# agents = [trainBot, randBot]\n",
        "\n",
        "numRuns = 150  # Number of runs to generate training data for per model\n",
        "\n",
        "for name, id in roshambo_bot_ids.items():\n",
        "  runData = []  # Contains data for each run\n",
        "\n",
        "  trainBot = BotAgent(num_actions, pyspiel.make_roshambo_bot(0, name), name=name)\n",
        "  agents = [trainBot, randBot]\n",
        "\n",
        "  # Run less times if this is a deterministic agent\n",
        "  # runTimes = 5 if name in deterministic_agents else numRuns\n",
        "  runTimes = numRuns\n",
        "\n",
        "  for run in tqdm(range(runTimes), desc=f\"Agent {name} ({id + 1} / {len(roshambo_bot_names)})\"):\n",
        "    # Reset variables for new run\n",
        "    time_step = env.reset()\n",
        "    randBot.restart()\n",
        "    if hasattr(trainBot, 'restart'):\n",
        "      trainBot.restart()\n",
        "\n",
        "    result = []  # Contains move data for this game\n",
        "\n",
        "    while not time_step.last():\n",
        "      actionList = [agent.step(time_step, is_evaluation=True).action for agent in agents]\n",
        "      result.append(actionList)\n",
        "      time_step = env.step(actionList)\n",
        "\n",
        "    runData.append(np.array(result, dtype=np.uint8))\n",
        "\n",
        "  if len(runData) != numRuns:\n",
        "    print(f\"Warning: length should be {numRuns} but is {len(runData)}\")\n",
        "\n",
        "  runData = np.array(runData, dtype=np.uint8)\n",
        "  print('Data shape:', runData.shape)\n",
        "\n",
        "  # Save np array containing results for this set to google drive\n",
        "  np.save(f'/content/drive/My Drive/CS486A4/AllBots_vs_random/{name}-VS-randbot-7.npy', runData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPadFgGTknGh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "emg",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
