{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51d9c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from tqdm import tqdm\n",
    "from typing import Final\n",
    "import itertools\n",
    "\n",
    "ID_TO_NAME: Final[dict] = {\n",
    "    0: 'actr_lag2_decay',\n",
    "    1: 'adddriftbot2',\n",
    "    2: 'addshiftbot3',\n",
    "    3: 'antiflatbot',\n",
    "    4: 'antirotnbot',\n",
    "    5: 'biopic',\n",
    "    6: 'boom',\n",
    "    7: 'copybot',\n",
    "    8: 'debruijn81',\n",
    "    9: 'driftbot',\n",
    "    10: 'flatbot3',\n",
    "    11: 'foxtrotbot',\n",
    "    12: 'freqbot2',\n",
    "    13: 'granite',\n",
    "    14: 'greenberg',\n",
    "    15: 'halbot',\n",
    "    16: 'inocencio',\n",
    "    17: 'iocainebot',\n",
    "    18: 'marble',\n",
    "    19: 'markov5',\n",
    "    20: 'markovbails',\n",
    "    21: 'mixed_strategy',\n",
    "    22: 'mod1bot',\n",
    "    23: 'multibot',\n",
    "    24: 'peterbot',\n",
    "    25: 'phasenbott',\n",
    "    26: 'pibot',\n",
    "    27: 'piedra',\n",
    "    28: 'predbot',\n",
    "    29: 'r226bot',\n",
    "    30: 'randbot',\n",
    "    31: 'robertot',\n",
    "    32: 'rockbot',\n",
    "    33: 'rotatebot',\n",
    "    34: 'russrocker4',\n",
    "    35: 'shofar',\n",
    "    36: 'sunCrazybot',\n",
    "    37: 'sunNervebot',\n",
    "    38: 'sweetrock',\n",
    "    39: 'switchalot',\n",
    "    40: 'switchbot',\n",
    "    41: 'textbot',\n",
    "    42: 'zq_move',\n",
    "}\n",
    "NAME_TO_ID: Final[dict] = {v: k for k, v in ID_TO_NAME.items()}\n",
    "\n",
    "WINDOW_SIZE = 200\n",
    "num_win_per_series = 1000-WINDOW_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38406587",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPSLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size=3, emb_dim=8, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_size, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 3)  # logits for R,P,S\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: (batch, T) of ints 0/1/2\n",
    "        emb = self.embed(x)\n",
    "        out, hidden = self.lstm(emb, hidden)  # out: (batch, T, hidden)\n",
    "        last = out[:, -1, :]\n",
    "        logits = self.fc(last)                 # (batch, T, 3)\n",
    "        return logits, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de7032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "PAD_TOKEN = 3  # 0,1,2 are moves; 3 is padding\n",
    "\n",
    "\n",
    "class RRPSDataset(Dataset):\n",
    "    def __init__(self, npz_path, seq_len=200):\n",
    "        \"\"\"\n",
    "        npz_path: path to rrps_lstm_data.npz\n",
    "        seq_len:  length of input context window\n",
    "        \"\"\"\n",
    "        data = np.load(npz_path, allow_pickle=True)\n",
    "        episodes = data[\"episodes\"]  # array of lists\n",
    "        self.seq_len = seq_len\n",
    "        self.samples = []  # list of (context_seq, target_move)\n",
    "\n",
    "        for ep in episodes:\n",
    "            moves = list(ep)\n",
    "            if len(moves) < 2:\n",
    "                continue  # too short, skip\n",
    "\n",
    "            # For each position t, predict move at t using moves before t\n",
    "            for t in range(1, len(moves)):\n",
    "                target = moves[t]\n",
    "                # context = last `seq_len` moves before t\n",
    "                start = max(0, t - seq_len)\n",
    "                ctx = moves[start:t]\n",
    "\n",
    "                # left-pad with PAD_TOKEN to fixed length\n",
    "                pad_len = seq_len - len(ctx)\n",
    "                ctx = [PAD_TOKEN] * pad_len + ctx\n",
    "\n",
    "                self.samples.append(\n",
    "                    (np.array(ctx, dtype=np.int64), int(target))\n",
    "                )\n",
    "\n",
    "        print(f\"Loaded {len(episodes)} episodes, built {len(self.samples)} samples.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ctx, tgt = self.samples[idx]\n",
    "        # return as torch tensors\n",
    "        return torch.tensor(ctx, dtype=torch.long), torch.tensor(tgt, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea868ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RRPSDataset(\"rrps_lstm_data.npz\", seq_len=200)\n",
    "\n",
    "# Split into train / val\n",
    "num_samples = len(dataset)\n",
    "train_size = int(0.9 * num_samples)\n",
    "val_size = num_samples - train_size\n",
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e78050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Apple Silicon GPU)\n",
      "[Train] Using device: mps\n",
      "Loaded 2150 episodes, built 2147850 samples.\n",
      "[Train] Train samples: 1933065, Val samples: 214785\n",
      "[Epoch 1/10] Train loss: 0.3917, acc: 0.5246 | Val loss: 0.3799, acc: 0.5401\n",
      "  -> New best val_acc=0.5401. Saved to rps_lstm.pt\n",
      "[Epoch 2/10] Train loss: 0.3772, acc: 0.5465 | Val loss: 0.3757, acc: 0.5495\n",
      "  -> New best val_acc=0.5495. Saved to rps_lstm.pt\n",
      "[Epoch 3/10] Train loss: 0.3713, acc: 0.5571 | Val loss: 0.3692, acc: 0.5629\n",
      "  -> New best val_acc=0.5629. Saved to rps_lstm.pt\n",
      "[Epoch 4/10] Train loss: 0.3643, acc: 0.5692 | Val loss: 0.3622, acc: 0.5725\n",
      "  -> New best val_acc=0.5725. Saved to rps_lstm.pt\n",
      "[Epoch 5/10] Train loss: 0.3571, acc: 0.5793 | Val loss: 0.3552, acc: 0.5837\n",
      "  -> New best val_acc=0.5837. Saved to rps_lstm.pt\n",
      "[Epoch 6/10] Train loss: 0.3518, acc: 0.5850 | Val loss: 0.3486, acc: 0.5885\n",
      "  -> New best val_acc=0.5885. Saved to rps_lstm.pt\n",
      "[Epoch 7/10] Train loss: 0.3487, acc: 0.5880 | Val loss: 0.3471, acc: 0.5900\n",
      "  -> New best val_acc=0.5900. Saved to rps_lstm.pt\n",
      "[Epoch 8/10] Train loss: 0.3451, acc: 0.5916 | Val loss: 0.3796, acc: 0.5463\n",
      "[Epoch 9/10] Train loss: 0.3537, acc: 0.5796 | Val loss: 0.3484, acc: 0.5890\n",
      "[Epoch 10/10] Train loss: 0.3549, acc: 0.5794 | Val loss: 0.3574, acc: 0.5762\n",
      "[Train] Done. Best val_acc=0.5900\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    This class implements the focal loss function for multi-class classification. The focal loss provided\n",
    "    by torch seems to only be for single class. This implementation is based on the one provided here:\n",
    "    https://discuss.pytorch.org/t/focal-loss-for-imbalanced-multi-class-classification-in-pytorch/61289\n",
    "    Some of the unnecessary functionality from the example has been removed.\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma: float = 2) -> None:\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, outputs, targets):\n",
    "        ce_loss = torch.nn.functional.cross_entropy(outputs, targets, reduction='none') # important to add reduction='none' to keep per-batch-item loss\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1-pt)**self.gamma * ce_loss).mean() # mean over the batch\n",
    "        return focal_loss  \n",
    "    \n",
    "loss_fn = FocalLoss()\n",
    "    \n",
    "\n",
    "def train_lstm(\n",
    "    npz_path=\"rrps_lstm_data.npz\",\n",
    "    seq_len=200,\n",
    "    batch_size=64,\n",
    "    num_epochs=10,\n",
    "    lr=1e-3,\n",
    "    val_split=0.1,\n",
    "    model_save_path=\"rps_lstm.pt\",\n",
    "):\n",
    "\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Apple Silicon GPU)\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Using CUDA GPU\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    print(f\"[Train] Using device: {device}\")\n",
    "\n",
    "    # 1. Dataset & loaders\n",
    "    dataset = RRPSDataset(npz_path, seq_len=seq_len)\n",
    "    n_total = len(dataset)\n",
    "    n_val = int(val_split * n_total)\n",
    "    n_train = n_total - n_val\n",
    "\n",
    "    train_ds, val_ds = random_split(dataset, [n_train, n_val])\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(f\"[Train] Train samples: {n_train}, Val samples: {n_val}\")\n",
    "\n",
    "    # 2. Model, optimizer\n",
    "    model = RPSLSTM(vocab_size=4, emb_dim=16, hidden_size=64).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # -------- TRAIN --------\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_count = 0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device, dtype=torch.long).long().view(-1)\n",
    "            # print(x.shape)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(x)         # (B, 3)\n",
    "            # logits = logits.view(-1, 3)\n",
    "            if logits.dim() != 2 or logits.size(1) != 3:\n",
    "                raise RuntimeError(f\"Expected logits shape (B,3), got {tuple(logits.shape)}\")\n",
    "            if y.dim() != 1 or y.size(0) != logits.size(0):\n",
    "                raise RuntimeError(f\"Expected target shape ({logits.size(0)},), got {tuple(y.shape)}\")\n",
    "            loss = loss_fn(logits, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == y).sum().item()\n",
    "            total_count += x.size(0)\n",
    "\n",
    "        train_loss = total_loss / total_count\n",
    "        train_acc = total_correct / total_count\n",
    "\n",
    "        # -------- VALIDATION --------\n",
    "        model.eval()\n",
    "        val_loss_total = 0.0\n",
    "        val_correct = 0\n",
    "        val_count = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                logits, _ = model(x)\n",
    "                loss = loss_fn(logits, y)\n",
    "\n",
    "                val_loss_total += loss.item() * x.size(0)\n",
    "                preds = logits.argmax(dim=1)\n",
    "                val_correct += (preds == y).sum().item()\n",
    "                val_count += x.size(0)\n",
    "\n",
    "        val_loss = val_loss_total / val_count if val_count > 0 else 0.0\n",
    "        val_acc = val_correct / val_count if val_count > 0 else 0.0\n",
    "\n",
    "        print(\n",
    "            f\"[Epoch {epoch}/{num_epochs}] \"\n",
    "            f\"Train loss: {train_loss:.4f}, acc: {train_acc:.4f} | \"\n",
    "            f\"Val loss: {val_loss:.4f}, acc: {val_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Save best model by validation accuracy\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"  -> New best val_acc={best_val_acc:.4f}. Saved to {model_save_path}\")\n",
    "\n",
    "    print(f\"[Train] Done. Best val_acc={best_val_acc:.4f}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "#  Run training\n",
    "# =========================\n",
    "train_lstm(\n",
    "    npz_path=\"rrps_lstm_data.npz\",\n",
    "    model_save_path=\"rps_lstm.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f8fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
